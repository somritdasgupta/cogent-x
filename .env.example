OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3:8b
EMBEDDING_MODEL_NAME=BAAI/bge-large-en-v1.5
CHROMA_PERSIST_DIRECTORY=./chroma_db
API_HOST=0.0.0.0
API_PORT=8000

# --- FastAPI Backend Configuration ---
FASTAPI_BACKEND_URL=

# --- Frontend API Configuration ---
# Base URL for the backend API (used by the React frontend)
# 
# LOCAL DEVELOPMENT: Leave empty to use Vite proxy (automatically forwards to http://localhost:8000)
# VITE_API_BASE_URL=
#
# PRODUCTION (Render/Cloud): Set this to your backend service URL
# IMPORTANT: No trailing slash!
# Example: VITE_API_BASE_URL=https://cogent-x-backend.onrender.com
# 
# This MUST be set when deploying frontend to Render/Vercel/Netlify
# Without this, frontend cannot connect to backend in production!
VITE_API_BASE_URL=

# --- Uptime Robot Status Page (Optional) ---
# Public status page URL that users can access to view system uptime

VITE_UPTIME_STATUS_PAGE=


# --- OpenAI Configuration (Optional) ---
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_MODEL=gpt-4

# --- Gemini Configuration (Optional) ---
# GEMINI_API_KEY=your_gemini_api_key_here
# GEMINI_MODEL=gemini-pro